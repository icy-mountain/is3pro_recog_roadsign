{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"pytorch_sSearchVer.ipynb ","provenance":[],"collapsed_sections":[],"toc_visible":true},"kernelspec":{"name":"python3","display_name":"Python 3"},"accelerator":"GPU"},"cells":[{"cell_type":"markdown","metadata":{"id":"AKRZVdocy1L6","colab_type":"text"},"source":["**これは完成したプログラムを実際に適用するファイルなので、大幅な変更を行う場合はコピーを作ろう**"]},{"cell_type":"code","metadata":{"id":"bMoMcSwbyp0M","colab_type":"code","colab":{}},"source":["from google.colab import drive\n","drive.mount('/content/drive')"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"1s-x3VrQWOpJ","colab_type":"text"},"source":["## For Sign Recognition Training"]},{"cell_type":"markdown","metadata":{"id":"OJIXwV7iK03K","colab_type":"text"},"source":["### import from localdata"]},{"cell_type":"code","metadata":{"id":"F2xFxpTPF1mx","colab_type":"code","colab":{}},"source":["from google.colab import files\n","files.upload()"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"iXMyRXVKIwoN","colab_type":"code","colab":{}},"source":["!unzip train_dir3class-balanced.zip"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"AS0aDKVjKsra","colab_type":"code","colab":{}},"source":["ls"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"Zl97oFz85YoX","colab_type":"code","colab":{}},"source":["# %cp -r \"/content/drive/My Drive/3is_project/GTRSB_kaggle/train_dir\" \"./\""],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"U3tpFZqTQ5f9","colab_type":"text"},"source":["###転移学習"]},{"cell_type":"code","metadata":{"id":"_Tk0VGoyfIg7","colab_type":"code","outputId":"0dafd3d8-0887-40b3-d0ab-ea3e4810d664","executionInfo":{"status":"ok","timestamp":1577340132015,"user_tz":-540,"elapsed":4744,"user":{"displayName":"Yusuke Kori","photoUrl":"","userId":"11428297377331214421"}},"colab":{"base_uri":"https://localhost:8080/","height":34}},"source":["import torch\n","print(torch.__version__)\n","import torchvision\n","import torch.nn as nn\n","import torch.nn.init as init\n","import torch.optim as optim\n","import torch.nn.functional as F\n","from torch.optim import lr_scheduler\n","from torchvision import datasets, models, transforms\n","import numpy as np\n","\n","# print(PIL.__version__)"],"execution_count":2,"outputs":[{"output_type":"stream","text":["1.3.1\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"imP9yg2OSovE","colab_type":"text"},"source":["### imagefolder dataloader cv2_imshow"]},{"cell_type":"code","metadata":{"id":"6VXuJYDpQ-9X","colab_type":"code","colab":{}},"source":["\n","data_transforms = {\n","    'train': transforms.Compose([\n","        transforms.Resize((64,64)),\n","        transforms.RandomAffine(5,shear=20,fillcolor=(127,127,127)),\n","        transforms.RandomApply([transforms.CenterCrop(51)],0.7),\n","        transforms.RandomApply([transforms.Pad(10)],0.7),\n","        transforms.Resize((64,64)),\n","        transforms.ToTensor(),\n","        transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n","    ])\n","}\n","\n","data_dir = './train_dir3class'\n","train_dataset = datasets.ImageFolder(data_dir,data_transforms['train'])\n","train_loader = torch.utils.data.DataLoader(dataset=train_dataset,batch_size=256,shuffle=True,num_workers=4)"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"p21h7BVWS0xS","colab_type":"code","colab":{}},"source":["from  google.colab.patches import cv2_imshow\n","import cv2\n","for i ,(images,labels) in enumerate(train_loader):\n","  # print(labels.numpy())\n","  # img = torchvision.utils.make_grid(images,padding=1)\n","  img = images[0]\n","  img = img.numpy()\n","  img = np.transpose(img,(1,2,0))\n","  # print(images.shape)\n","  # print(images[0])\n","  cv2_imshow(cv2.cvtColor(img*255,cv2.COLOR_RGB2BGR))\n","  if(i>40):\n","    break"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"KH06VjXgSmc3","colab_type":"text"},"source":["### train"]},{"cell_type":"code","metadata":{"id":"nYYOMLWanDLy","colab_type":"code","colab":{}},"source":["device = \"cuda\" if torch.cuda.is_available() else \"cpu\""],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"bhCdnxZBz7G7","colab_type":"code","colab":{}},"source":["class My_model(nn.Module):\n","  def __init__(self):\n","    super(My_model,self).__init__()\n","    self.vgg = models.vgg19_bn(pretrained=True)\n","    for param in self.vgg.features[0:26].parameters():\n","       param.requires_grad = False\n","    for param in self.vgg.features[26:53].parameters():\n","       param.requires_grad = True\n","    num_ftrs = self.vgg.classifier[6].in_features\n","    self.vgg.classifier[6] = nn.Linear(num_ftrs, 3)\n","    \n","    \n","  def forward(self,x):\n","    x = self.vgg(x)\n","    # x = torch.sigmoid(x)\n","    return x\n"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"i_77rQXxRbcS","colab_type":"code","colab":{}},"source":["# model = models.vgg19(pretrained=True)\n","# model = models.vgg19(pretrained=False)\n","# model = model.to(device)\n","# model\n","model = My_model()\n","model = model.to(device)"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"GhmRR5HXcvFP","colab_type":"code","colab":{}},"source":["for p in model.vgg.classifier.parameters():\n","  print(p.requires_grad)"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"Ob4rsaz-99XE","colab_type":"code","colab":{}},"source":["model"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"qsLnHZKFpWxR","colab_type":"code","colab":{}},"source":["criterion = nn.CrossEntropyLoss()\n","# optimizer = optim.SGD(model.parameters(), lr=1e-4, momentum=0.9, weight_decay=5e-4)\n","optimizer = optim.Adam(model.parameters(), lr=1e-5, weight_decay=5e-4)\n","lr_scheduler = torch.optim.lr_scheduler.StepLR(optimizer, step_size=10, gamma=0.1)"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"6pYkLpWyqSBE","colab_type":"code","colab":{}},"source":["import nvidia_smi\n","!nvidia-smi"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"KA9X6ArSUJnu","colab_type":"code","colab":{}},"source":["!ps -elf | grep python"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"X2EX5N5nr73h","colab_type":"code","colab":{}},"source":["!ps aux\n","!kill -9 19"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"40D2QFakR_zq","colab_type":"code","outputId":"593b4af3-5093-427f-9345-7eb877ea299f","executionInfo":{"status":"ok","timestamp":1576564238442,"user_tz":-540,"elapsed":161822,"user":{"displayName":"Yusuke Kori","photoUrl":"","userId":"11428297377331214421"}},"colab":{"base_uri":"https://localhost:8080/","height":104}},"source":["num_epochs = 5\n","train_loss_list = []\n","train_acc_list = []\n","\n","for epoch in range(num_epochs):\n","    train_loss = 0\n","    train_acc = 0\n","    \n","    #train\n","    model.train()\n","    for i, (images, labels) in enumerate(train_loader):\n","      images,labels = images.to(device),labels.to(device)\n","      optimizer.zero_grad()\n","      outputs = model(images)\n","      loss = criterion(outputs, labels)\n","      train_loss += loss.item()\n","      train_acc += (outputs.max(1)[1] == labels).sum().item()\n","      loss.backward()\n","      optimizer.step()\n","    \n","    avg_train_loss = train_loss / len(train_loader.dataset)\n","    avg_train_acc = train_acc / len(train_loader.dataset)\n","\n","    print ('Epoch [{}/{}], Loss: {loss:.4f}, Acc: {acc:.4f}, lr：{learning_rate}' \n","                       .format(epoch+1, num_epochs , loss=avg_train_loss, acc=avg_train_acc,learning_rate=optimizer.param_groups[0][\"lr\"]))\n","    #学習率調整\n","    lr_scheduler.step()\n","    train_loss_list.append(avg_train_loss)\n","    train_acc_list.append(avg_train_acc)"],"execution_count":0,"outputs":[{"output_type":"stream","text":["Epoch [1/5], Loss: 0.0025, Acc: 0.7769, lr：1e-05\n","Epoch [2/5], Loss: 0.0003, Acc: 0.9833, lr：1e-05\n","Epoch [3/5], Loss: 0.0001, Acc: 0.9956, lr：1e-05\n","Epoch [4/5], Loss: 0.0000, Acc: 0.9976, lr：1e-05\n","Epoch [5/5], Loss: 0.0000, Acc: 0.9997, lr：1e-05\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"LjqDkyFXstxE","colab_type":"text"},"source":["### model save ,load"]},{"cell_type":"code","metadata":{"id":"BKXoCIe9S6iq","colab_type":"code","colab":{}},"source":["torch.save(model.state_dict(), '/content/drive/My Drive/3is_project/GTRSB_kaggle/models/12_17_fined.model')"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"OylcMDfKwOJd","colab_type":"code","outputId":"ef7afb95-74f8-4b48-ee5b-ef580639bbb2","executionInfo":{"status":"ok","timestamp":1577340197203,"user_tz":-540,"elapsed":31514,"user":{"displayName":"Yusuke Kori","photoUrl":"","userId":"11428297377331214421"}},"colab":{"base_uri":"https://localhost:8080/","height":69}},"source":["# 12_11_fined3 -> sigmoid;  12_11_fined2 -> linear\n","model = My_model()\n","param = torch.load('/content/drive/My Drive/3is_project/GTRSB_kaggle/models/12_17_fined.model')\n","model.load_state_dict(param)"],"execution_count":6,"outputs":[{"output_type":"stream","text":["Downloading: \"https://download.pytorch.org/models/vgg19_bn-c79401a0.pth\" to /root/.cache/torch/checkpoints/vgg19_bn-c79401a0.pth\n","100%|██████████| 548M/548M [00:09<00:00, 61.9MB/s]\n"],"name":"stderr"},{"output_type":"execute_result","data":{"text/plain":["<All keys matched successfully>"]},"metadata":{"tags":[]},"execution_count":6}]},{"cell_type":"code","metadata":{"colab_type":"code","outputId":"ea15cff6-04df-4165-8717-96aa0ef9ced4","executionInfo":{"status":"ok","timestamp":1576510493618,"user_tz":-540,"elapsed":3697,"user":{"displayName":"Yusuke Kori","photoUrl":"","userId":"11428297377331214421"}},"id":"IUPupMjjonfC","colab":{"base_uri":"https://localhost:8080/","height":69}},"source":["ls '/content/drive/My Drive/3is_project/GTRSB_kaggle/models/'"],"execution_count":0,"outputs":[{"output_type":"stream","text":["12_11_fined2.model  12_15_fined.model      class3_12_6_fined.h5\n","12_11_fined3.model  class3_11_28_fined.h5  test2.model\n","12_11_fined.model   class3_11_28.h5        test.model\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"3uZMKMGs0ypA","colab_type":"text"},"source":["## area detection"]},{"cell_type":"markdown","metadata":{"colab_type":"text","id":"xWtzq8KGpXBD"},"source":["### image cuts"]},{"cell_type":"code","metadata":{"colab_type":"code","id":"2sU6OIwGpXBJ","colab":{}},"source":["def upCut(path,verbose=False):\n","  import numpy as np\n","  import cv2\n","  import time\n","  if type(path) == str:\n","    start= time.time()\n","    img = cv2.imread(path)\n","    print(f\"file load:{time.time() - start}\")\n","    img = cv2.resize(img , dsize=(640, 480))\n","  else: \n","    img = path\n","  \n","  img = img[0:int(len(img)/3),:,:]\n","  if verbose:\n","   cv2.imshow(img)\n","  return img\n","\n","def rightCut(path,ratio,idx,verbose=False):\n","  from google.colab.patches import cv2_imshow\n","  import numpy as np\n","  import cv2\n","  if type(path) == str:\n","    img = cv2.imread(path)\n","    img = cv2.resize(img , dsize=(640, 480))\n","  else: \n","    img = path \n","  img = img[:,int(len(img[0])/ratio)*idx:int(len(img[0])/ratio)*(idx+1),:]\n","  if verbose:\n","    cv2_imshow(img)\n","  return img"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"jZ0_96x4pbpa","colab_type":"text"},"source":["### simplize"]},{"cell_type":"code","metadata":{"id":"6mPv5D9-poTa","colab_type":"code","colab":{}},"source":["def simplize(path,verbose=False): \n","  from google.colab.patches import cv2_imshow\n","  import numpy as np\n","  import cv2\n","  if type(path) == str:\n","    img = cv2.imread(path)\n","    img = cv2.resize(img , dsize=(640, 480))\n","  else: \n","    img = path\n","  ## HSVFULLじゃないことに注意！！\n","  hsv = cv2.cvtColor(img ,cv2.COLOR_BGR2HSV)\n","  ## red 160 - 19 yellow 20-39 green 40 - 79 cyan 80 - 99 blue 100 - 139  biolet 140-159  \n","  hsv[:,:,0]=np.where( (160 <= hsv[:,:,0]) | (hsv[:,:,0] <= 19),0,hsv[:,:,0])#red\n","  hsv[:,:,0]=np.where( (20 <= hsv[:,:,0]) & (hsv[:,:,0] <= 39),30,hsv[:,:,0])#yellow\n","  hsv[:,:,0]=np.where( (40 <= hsv[:,:,0]) & (hsv[:,:,0] <= 79),60,hsv[:,:,0])#green\n","  hsv[:,:,0]=np.where( (80 <= hsv[:,:,0]) & (hsv[:,:,0] <= 99),90,hsv[:,:,0])#cyan\n","  hsv[:,:,0]=np.where( (100 <= hsv[:,:,0]) & (hsv[:,:,0] <= 139),120,hsv[:,:,0])#blue\n","  hsv[:,:,0]=np.where( (140 <= hsv[:,:,0]) & (hsv[:,:,0] <= 159),150,hsv[:,:,0])#violet\n","  ### 彩度の範囲を広げると白色が検出しづらくなる。明度を広げると薄い色が検出しづらくなる。\n","  hsv[:,:,1]=np.where( (hsv[:,:,1] <= 60) & (160 <= hsv[:,:,2]  )  ,0,hsv[:,:,1]) #white \n","  hsv[:,:,2]=np.where( hsv[:,:,2] <=  100, 0,hsv[:,:,2]) #black # flatten all colors\n","  if verbose:\n","    cv2_imshow(cv2.cvtColor(hsv,cv2.COLOR_HSV2BGR))\n","  return cv2.cvtColor(hsv,cv2.COLOR_HSV2BGR)\n"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"fEgVMPHlfA4f","colab_type":"code","colab":{}},"source":["def rb_filter(path,verbose=False):\n","  if type(path) == str:\n","    img = cv2.imread(path)\n","    img = cv2.resize(img , dsize=(640, 480))\n","  else: \n","    img = path\n","  if verbose:\n","    cv2_imshow(img)\n","  hsv = cv2.cvtColor(img, cv2.COLOR_BGR2HSV)\n","  hsv[:,:,2]=np.where( ((hsv[:,:,0] == 0)|(hsv[:,:,0]==150)|(hsv[:,:,0] == 120)|(hsv[:,:,0]==90)) & (hsv[:,:,1]  > 30 ), 255,0)\n","  img = cv2.cvtColor(hsv,cv2.COLOR_HSV2BGR)\n","  if verbose:\n","    cv2_imshow(img)\n","  return img\n"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"UiXaZ23b40u2","colab_type":"text"},"source":["###selective search"]},{"cell_type":"code","metadata":{"id":"GP09ne4ATTzf","colab_type":"code","colab":{}},"source":["import skimage.io\n","import skimage.feature\n","import skimage.color\n","import skimage.transform\n","import skimage.util\n","import skimage.segmentation\n","import numpy\n","import time\n","\n","def _generate_segments(im_orig, scale, sigma, min_size):\n","    \"\"\"\n","        segment smallest regions by the algorithm of Felzenswalb and\n","        Huttenlocher\n","    \"\"\"\n","\n","    # open the Image\n","    im_mask = skimage.segmentation.felzenszwalb(\n","        im_orig, scale=scale, sigma=sigma,\n","        min_size=min_size)\n","\n","    # merge mask channel to the image as a 4th channel\n","\n","    im_orig = numpy.append(\n","        im_orig, numpy.zeros((len(im_orig),len(im_orig[0])))[:, :, numpy.newaxis], axis=2)\n","    im_orig[:, :, 3] = im_mask\n","    return im_orig\n","\n","\n","def _sim_colour(r1, r2):\n","    \"\"\"\n","        calculate the sum of histogram intersection of colour\n","    \"\"\"\n","    return sum([min(a, b) for a, b in zip(r1[\"hist_c\"], r2[\"hist_c\"])])\n","\n","\n","def _sim_texture(r1, r2):\n","    \"\"\"\n","        calculate the sum of histogram intersection of texture\n","    \"\"\"\n","    return sum([min(a, b) for a, b in zip(r1[\"hist_t\"], r2[\"hist_t\"])])\n","\n","\n","def _sim_size(r1, r2, imsize):\n","    \"\"\"\n","        calculate the size similarity over the image\n","    \"\"\"\n","    return 1.0 - (r1[\"size\"] + r2[\"size\"]) / imsize\n","\n","\n","def _sim_fill(r1, r2, imsize):\n","    \"\"\"\n","        calculate the fill similarity over the image\n","    \"\"\"\n","    bbsize = (\n","        (max(r1[\"max_x\"], r2[\"max_x\"]) - min(r1[\"min_x\"], r2[\"min_x\"]))\n","        * (max(r1[\"max_y\"], r2[\"max_y\"]) - min(r1[\"min_y\"], r2[\"min_y\"]))\n","    )\n","    return 1.0 - (bbsize - r1[\"size\"] - r2[\"size\"]) / imsize\n","\n","\n","def _calc_sim(r1, r2, imsize):\n","    return (_sim_colour(r1, r2) + _sim_texture(r1, r2)\n","            + _sim_size(r1, r2, imsize) + _sim_fill(r1, r2, imsize))\n","\n","\n","def _calc_colour_hist(img):\n","    BINS = 25\n","    hist = numpy.array([])\n","    for colour_channel in (0, 1, 2):\n","        # extracting one colour channel\n","        c = img[:, colour_channel]\n","        # calculate histogram for each colour and join to the result\n","        hist = numpy.concatenate(\n","            [hist] + [numpy.histogram(c, BINS, (0.0, 255.0))[0]])\n","    # L1 normalize\n","    hist = hist / len(img)\n","\n","    return hist\n","\n","\n","def _calc_texture_gradient(img):\n","    ret = numpy.zeros((img.shape[0], img.shape[1], img.shape[2]))\n","    for colour_channel in (0, 1, 2):\n","        ret[:, :, colour_channel] = skimage.feature.local_binary_pattern(\n","            img[:, :, colour_channel], 8, 1.0)\n","    return ret\n","\n","\n","def _calc_texture_hist(img):\n","    BINS = 10\n","    hist = numpy.array([])\n","\n","    for colour_channel in (0, 1, 2):\n","\n","        # mask by the colour channel\n","        fd = img[:, colour_channel]\n","\n","        # calculate histogram for each orientation and concatenate them all\n","        # and join to the result\n","        hist = numpy.concatenate(\n","            [hist] + [numpy.histogram(fd, BINS, (0.0, 1.0))[0]])\n","\n","    # L1 Normalize\n","    hist = hist / len(img)\n","\n","    return hist\n","\n","\n","def _extract_regions(img):\n","    R = {}\n","    hsv = skimage.color.rgb2hsv(img[:, :, :3])\n","    for y, i in enumerate(img):\n","        for x, (r, g, b, l) in enumerate(i):\n","            if l not in R:\n","                R[l] = {\n","                    \"min_x\": 0xffff, \"min_y\": 0xffff,\n","                    \"max_x\": 0, \"max_y\": 0, \"labels\": l}\n","            if R[l][\"min_x\"] > x:\n","                R[l][\"min_x\"] = x\n","            if R[l][\"min_y\"] > y:\n","                R[l][\"min_y\"] = y\n","            if R[l][\"max_x\"] < x:\n","                R[l][\"max_x\"] = x\n","            if R[l][\"max_y\"] < y:\n","                R[l][\"max_y\"] = y\n","    tex_grad = _calc_texture_gradient(img)\n","    for k, v in list(R.items()):\n","        masked_pixels = hsv[:, :, :][img[:, :, 3] == k]\n","        R[k][\"size\"] = len(masked_pixels / 4)\n","        R[k][\"hist_c\"] = _calc_colour_hist(masked_pixels)\n","        R[k][\"hist_t\"] = _calc_texture_hist(tex_grad[:, :][img[:, :, 3] == k])\n","    return R\n","\n","\n","def _extract_neighbours(regions):\n","    def intersect(a, b):\n","        if (a[\"min_x\"] < b[\"min_x\"] < a[\"max_x\"]\n","                and a[\"min_y\"] < b[\"min_y\"] < a[\"max_y\"]) or (\n","            a[\"min_x\"] < b[\"max_x\"] < a[\"max_x\"]\n","                and a[\"min_y\"] < b[\"max_y\"] < a[\"max_y\"]) or (\n","            a[\"min_x\"] < b[\"min_x\"] < a[\"max_x\"]\n","                and a[\"min_y\"] < b[\"max_y\"] < a[\"max_y\"]) or (\n","            a[\"min_x\"] < b[\"max_x\"] < a[\"max_x\"]\n","                and a[\"min_y\"] < b[\"min_y\"] < a[\"max_y\"]):\n","            return True\n","        return False\n","    R = list(regions.items())\n","    neighbours = []\n","    for cur, a in enumerate(R[:-1]):\n","        for b in R[cur + 1:]:\n","            if intersect(a[1], b[1]):\n","                neighbours.append((a, b))\n","    return neighbours\n","def _merge_regions(r1, r2):\n","    new_size = r1[\"size\"] + r2[\"size\"]\n","    rt = {\n","        \"min_x\": min(r1[\"min_x\"], r2[\"min_x\"]),\n","        \"min_y\": min(r1[\"min_y\"], r2[\"min_y\"]),\n","        \"max_x\": max(r1[\"max_x\"], r2[\"max_x\"]),\n","        \"max_y\": max(r1[\"max_y\"], r2[\"max_y\"]),\n","        \"size\": new_size,\n","        \"hist_c\": (\n","            r1[\"hist_c\"] * r1[\"size\"] + r2[\"hist_c\"] * r2[\"size\"]) / new_size,\n","        \"hist_t\": (\n","            r1[\"hist_t\"] * r1[\"size\"] + r2[\"hist_t\"] * r2[\"size\"]) / new_size,\n","        \"labels\": r1[\"labels\"] + r2[\"labels\"]\n","    }\n","    return rt\n","def selective_search(im_orig, scale=1.0, sigma=0.8, min_size=50):\n","    assert im_orig.shape[2] == 3, \"3ch image is expected\"\n","    img = _generate_segments(im_orig, scale, sigma, min_size)\n","    if img is None:\n","        return None, {}\n","    imsize = img.shape[0] * img.shape[1]\n","    R = _extract_regions(img)\n","    neighbours = _extract_neighbours(R)\n","    S = {}\n","    for (ai, ar), (bi, br) in neighbours:\n","        S[(ai, bi)] = _calc_sim(ar, br, imsize)\n","    while S != {}:\n","        i, j = sorted(S.items(), key=lambda i: i[1])[-1][0]\n","        t = max(R.keys()) + 1.0\n","        R[t] = _merge_regions(R[i], R[j])\n","        key_to_delete = []\n","        for k, v in list(S.items()):\n","            if (i in k) or (j in k):\n","                key_to_delete.append(k)\n","        for k in key_to_delete:\n","            del S[k]\n","        for k in [a for a in key_to_delete if a != (i, j)]:\n","            n = k[1] if k[0] in (i, j) else k[0]\n","            S[(t, n)] = _calc_sim(R[t], R[n], imsize)\n","    regions = []\n","    for r in R.values():\n","      w = r['max_x'] - r['min_x']\n","      h = r['max_y'] - r['min_y']\n","      ratio = h/w if w>=h else w/h\n","      if( ratio>=0.8 and w*h > 1000 and w*h < 5000):\n","        regions.append({\n","              'x_':r['min_x'], \n","              'y_':r['min_y'],\n","              '_x':r['max_x'],\n","              '_y':r['max_y'],\n","              'area': w*h,\n","        })\n","    sort = sorted(regions, key=lambda x:x[\"area\"],reverse=True)\n","    idx=0\n","    ## non maximum suppression\n","    for i1, r1 in enumerate(sort):\n","      idx = i1 + 1\n","      for r2 in sort[i1+1:]:\n","        if r1[\"x_\"] <= r2[\"x_\"] and r1[\"_x\"] >= r2[\"_x\"] and r1[\"y_\"] <= r2[\"y_\"] and r1[\"_y\"] >= r2[\"_y\"]:    \n","          del sort[idx]\n","          idx -= 1\n","        idx += 1 \n","    return img, sort"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"5cUP0Z-ZTL-1","colab_type":"text"},"source":["### road sign recog"]},{"cell_type":"code","metadata":{"id":"uUi7wgJTrBIq","colab_type":"code","colab":{}},"source":["device= \"cuda\"\n","model = model.eval()\n","model = model.to(device)\n","def classify_torch(model,detected,exam=True):\n","  from google.colab.patches import cv2_imshow\n","  import cv2\n","  import time\n","  if exam:\n","    cv2_imshow(detected)\n","  image = cv2.cvtColor(detected , cv2.COLOR_BGR2RGB)\n","  trf = transforms.Compose([\n","    transforms.ToPILImage(),\n","    transforms.Resize((64,64)), \n","    transforms.ToTensor(), \n","    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n","    ])\n","  image=trf(image)\n","  image = image.view(1,3,64,64)\n","  image = image.float()\n","  image = image.to(device)\n","  \n","  start = time.time()\n","  output= model(image)\n","  print(f\"recog time: {time.time()-start}\")\n","  clas = pprint(output,exam)\n","  return clas"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"k6GJeMGNs9ag","colab_type":"code","colab":{}},"source":["def classify(model,detected,exam=True):\n","  from google.colab.patches import cv2_imshow\n","  import cv2\n","  import time\n","  image = cv2.resize(detected , dsize=(64, 64))\n","  if exam:\n","    cv2_imshow(image)\n","  image = cv2.cvtColor(image , cv2.COLOR_BGR2RGB)\n","  image = image.reshape((1,) + image.shape)\n","  image = image / 255\n","  start = time.time()\n","  clas = pprint(model.predict(image),exam)\n","  print(f\" recog time:{time.time() - start}\")\n","  return clas\n"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"BnXaxvdztHYK","colab_type":"code","colab":{}},"source":["def pprint(arr,exam=True):\n","  print(f\" {arr}\")\n","  diff = abs(arr[0][0]-arr[0][1]-arr[0][2])\n","  idx = arr[0].argmax()\n","  if exam:\n","    print(f\" difference = {diff}\")\n","  if arr[0][idx]<5 or arr[0][(idx+1)%3]>0 or arr[0][(idx+2)%3]>0 :\n","  # if diff<0.7 :\n","    print(\" Others\")\n","    return 3\n","  elif arr.argmax() == 0:\n","    print(\" Speed restriction 30\")\n","    return 0\n","  elif arr.argmax() == 1:\n","    print(\" GO\")\n","    return 1\n","  elif arr.argmax() == 2:\n","    print(\" STOP\")\n","    return 2"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"6seeNyYHfPpp","colab_type":"text"},"source":["**対象を一つ検出したら検索を切り上げる**"]},{"cell_type":"code","metadata":{"id":"tavwZxO7qI2a","colab_type":"code","outputId":"54261fa7-142c-4fb7-f0a2-c80c5af63e8d","executionInfo":{"status":"ok","timestamp":1576568730330,"user_tz":-540,"elapsed":1088,"user":{"displayName":"Yusuke Kori","photoUrl":"","userId":"11428297377331214421"}},"colab":{"base_uri":"https://localhost:8080/","height":227}},"source":["def s_search(path,exam=True):\n","  from google.colab.patches import cv2_imshow\n","  import numpy as np\n","  import cv2\n","  import time \n","  print(f\"\\nimage path = {path}\")\n","  s = time.perf_counter()\n","  cut = rightCut(upCut(pth),3,idx=0,verbose=False)\n","  img = simplize(cut,False)\n","  img = rb_filter(img,False)\n","  img = cv2.medianBlur(img,5)\n","  img = cv2.GaussianBlur(img,(17,17),0,0)\n","  print(f\"maeshori:{time.perf_counter()-s}\")\n","  print(\"_______SEARCH START_______\")\n","  start = time.perf_counter()\n","  _, regions = selective_search(img.astype(np.float64), scale=3000, sigma=0.0, min_size=100)\n","  print(f\" search time:{time.perf_counter() - start}\")\n","  for r in regions:\n","    start = time.perf_counter()\n","    c = classify_torch(model,cut[r[\"y_\"]:r[\"_y\"],r[\"x_\"]:r[\"_x\"],:],exam)\n","    print(f\"recog time:{time.perf_counter() - start}\")\n","    if c!=3:\n","      return c\n","  return c\n","# pth = \"/content/drive/My Drive/3is_project/GTRSB_kaggle/vali_dir00_speed/speed_img_000.jpg\"\n","pth = \"/content/drive/My Drive/3is_project/GTRSB_kaggle/micon_images/micon_img_320.jpg\"\n","# pth = \"/content/drive/My Drive/3is_project/GTRSB_kaggle/micon_images/micon_img_520.jpg\"\n","# pth = \"/content/drive/My Drive/3is_project/GTRSB_kaggle/output2.jpg\"\n","# pth = \"/content/drive/My Drive/3is_project/GTRSB_kaggle/win_images/20191201/win_img_000.jpg\"\n","# pth = \"/content/drive/My Drive/3is_project/GTRSB_kaggle/win_images/20191201/win_img_010.jpg\"\n","# pth = \"/content/drive/My Drive/3is_project/GTRSB_kaggle/win_images/20191201/win_img_020.jpg\"\n","# pth = '/content/drive/My Drive/3is_project/GTRSB_kaggle/win_images/20191129_17_03_16/win_img_1600.jpg'\n","import time\n","start=time.perf_counter()\n","sign = s_search(pth,False)\n","print(f\"about time:{time.perf_counter() -start}\")\n","print(sign)"],"execution_count":0,"outputs":[{"output_type":"stream","text":["\n","image path = /content/drive/My Drive/3is_project/GTRSB_kaggle/micon_images/micon_img_320.jpg\n","file load:0.023802757263183594\n","maeshori:0.03359986299983575\n","_______SEARCH START_______\n"," search time:0.1780810919990472\n","recog time: 0.0041162967681884766\n"," tensor([[ 6.6357, -6.9466, -2.5718]], device='cuda:0', grad_fn=<AddmmBackward>)\n"," Speed restriction 30\n","recog time:0.0224391209994792\n","about time:0.23584562399992137\n","0\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"prQCXtUDb9CA","colab_type":"text"},"source":["**動作確認用**"]},{"cell_type":"code","metadata":{"id":"0m5-UbsWbYeH","colab_type":"code","outputId":"c6550b97-0f63-4a88-8440-f75dd907abf5","executionInfo":{"status":"ok","timestamp":1576564306791,"user_tz":-540,"elapsed":51783,"user":{"displayName":"Yusuke Kori","photoUrl":"","userId":"11428297377331214421"}},"colab":{"base_uri":"https://localhost:8080/","height":1000,"output_embedded_package_id":"1pyHHitFaBp2wwyjnOYnplrW1oZ1tq9lQ"}},"source":["def s_search(path,exam=True):\n","  from google.colab.patches import cv2_imshow\n","  import numpy as np\n","  import cv2\n","  # import selectivesearch\n","  import time \n","  begin = time.time()\n","  print(f\"\\nimage path = {path}\")\n","  for j in range(3):\n","    s = time.time()\n","    cut = rightCut(upCut(path),3,idx=j,verbose=False)\n","    img = simplize(cut,True)\n","    img = rb_filter(img,False)\n","    img = cv2.medianBlur(img,5)\n","    img = cv2.GaussianBlur(img,(17,17),0,0)\n","    print(f\"maeshori:{time.time()-s}\")\n","    print(\"_______SEARCH START_______\")\n","    start = time.time()\n","    _, regions = selective_search(img.astype(np.float64), scale=3000, sigma=0, min_size=100)\n","    print(f\" search time:{time.time() - start}\")\n","    for r in regions:\n","      start = time.time()\n","      c = classify_torch(model,cut[r[\"y_\"]:r[\"_y\"],r[\"x_\"]:r[\"_x\"],:],exam)\n","      print(f\"recog time:{time.time() - start}\")\n","      if c!=3:\n","        cv2.rectangle(cut, (r[\"x_\"], r[\"y_\"]), (r[\"_x\"], r[\"_y\"]), (0, 0, 255), 2)\n","        cv2_imshow(cut)\n","    print(f\"about time:{time.time() -begin}\")\n","\n","import os \n","dire = \"/content/drive/My Drive/3is_project/GTRSB_kaggle/micon_images/\"\n","images = os.listdir(dire)\n","for i in images:\n","  img = dire + i\n","  s_search(img,False)"],"execution_count":0,"outputs":[{"output_type":"display_data","data":{"text/plain":"Output hidden; open in https://colab.research.google.com to view."},"metadata":{}}]},{"cell_type":"code","metadata":{"id":"aJfXV5wNpCWG","colab_type":"code","colab":{}},"source":[""],"execution_count":0,"outputs":[]}]}