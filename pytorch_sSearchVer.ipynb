{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"pytorch_sSearchVer.ipynb ","provenance":[],"collapsed_sections":[],"toc_visible":true},"kernelspec":{"name":"python3","display_name":"Python 3"},"accelerator":"GPU"},"cells":[{"cell_type":"markdown","metadata":{"id":"AKRZVdocy1L6","colab_type":"text"},"source":["**これは完成したプログラムを実際に適用するファイルなので、大幅な変更を行う場合はコピーを作ろう**"]},{"cell_type":"code","metadata":{"id":"bMoMcSwbyp0M","colab_type":"code","outputId":"750d6dee-6063-4106-e29f-3eece6d3a0a9","executionInfo":{"status":"ok","timestamp":1576793068654,"user_tz":-540,"elapsed":39600,"user":{"displayName":"Yusuke Kori","photoUrl":"","userId":"11428297377331214421"}},"colab":{"base_uri":"https://localhost:8080/","height":124}},"source":["from google.colab import drive\n","drive.mount('/content/drive')"],"execution_count":1,"outputs":[{"output_type":"stream","text":["Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3aietf%3awg%3aoauth%3a2.0%3aoob&response_type=code&scope=email%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdocs.test%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive.photos.readonly%20https%3a%2f%2fwww.googleapis.com%2fauth%2fpeopleapi.readonly\n","\n","Enter your authorization code:\n","··········\n","Mounted at /content/drive\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"1s-x3VrQWOpJ","colab_type":"text"},"source":["## For Sign Recognition Training"]},{"cell_type":"markdown","metadata":{"id":"OJIXwV7iK03K","colab_type":"text"},"source":["### import from localdata"]},{"cell_type":"code","metadata":{"id":"F2xFxpTPF1mx","colab_type":"code","outputId":"c8599d7c-c539-4288-df85-dd24d7826c14","executionInfo":{"status":"error","timestamp":1576793339713,"user_tz":-540,"elapsed":247209,"user":{"displayName":"Yusuke Kori","photoUrl":"","userId":"11428297377331214421"}},"colab":{"resources":{"http://localhost:8080/nbextensions/google.colab/files.js":{"data":"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","ok":true,"headers":[["content-type","application/javascript"]],"status":200,"status_text":""}},"base_uri":"https://localhost:8080/","height":397}},"source":["from google.colab import files\n","files.upload()"],"execution_count":2,"outputs":[{"output_type":"display_data","data":{"text/html":["\n","     <input type=\"file\" id=\"files-6e8c816f-9a5a-45b7-bb4a-90e636325ac6\" name=\"files[]\" multiple disabled />\n","     <output id=\"result-6e8c816f-9a5a-45b7-bb4a-90e636325ac6\">\n","      Upload widget is only available when the cell has been executed in the\n","      current browser session. Please rerun this cell to enable.\n","      </output>\n","      <script src=\"/nbextensions/google.colab/files.js\"></script> "],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{"tags":[]}},{"output_type":"stream","text":["Saving train_dir3class-balanced.zip to train_dir3class-balanced.zip\n"],"name":"stdout"},{"output_type":"error","ename":"KeyboardInterrupt","evalue":"ignored","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)","\u001b[0;32m<ipython-input-2-5c2e8a8d365b>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mgoogle\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolab\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mfiles\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mfiles\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/google/colab/files.py\u001b[0m in \u001b[0;36mupload\u001b[0;34m()\u001b[0m\n\u001b[1;32m     70\u001b[0m     result = _output.eval_js(\n\u001b[1;32m     71\u001b[0m         'google.colab._files._uploadFilesContinue(\"{output_id}\")'.format(\n\u001b[0;32m---> 72\u001b[0;31m             output_id=output_id))\n\u001b[0m\u001b[1;32m     73\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'action'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0;34m'append'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     74\u001b[0m       \u001b[0;31m# JS side uses a generator of promises to process all of the files- some\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/google/colab/output/_js.py\u001b[0m in \u001b[0;36meval_js\u001b[0;34m(script, ignore_result)\u001b[0m\n\u001b[1;32m     37\u001b[0m   \u001b[0;32mif\u001b[0m \u001b[0mignore_result\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     38\u001b[0m     \u001b[0;32mreturn\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 39\u001b[0;31m   \u001b[0;32mreturn\u001b[0m \u001b[0m_message\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_reply_from_input\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrequest_id\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     40\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     41\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/google/colab/_message.py\u001b[0m in \u001b[0;36mread_reply_from_input\u001b[0;34m(message_id, timeout_sec)\u001b[0m\n\u001b[1;32m     99\u001b[0m     \u001b[0mreply\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_read_next_input_message\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    100\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mreply\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0m_NOT_READY\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mreply\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdict\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 101\u001b[0;31m       \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msleep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0.025\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    102\u001b[0m       \u001b[0;32mcontinue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    103\u001b[0m     if (reply.get('type') == 'colab_reply' and\n","\u001b[0;31mKeyboardInterrupt\u001b[0m: "]}]},{"cell_type":"code","metadata":{"id":"iXMyRXVKIwoN","colab_type":"code","colab":{}},"source":["!unzip train_dir3class-balanced.zip"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"AS0aDKVjKsra","colab_type":"code","outputId":"674c5f13-52af-45b2-f472-21882fbbaeab","executionInfo":{"status":"ok","timestamp":1576560474253,"user_tz":-540,"elapsed":5873,"user":{"displayName":"Yusuke Kori","photoUrl":"","userId":"11428297377331214421"}},"colab":{"base_uri":"https://localhost:8080/","height":69}},"source":["ls"],"execution_count":0,"outputs":[{"output_type":"stream","text":[" \u001b[0m\u001b[01;34mdrive\u001b[0m/            'train_dir3class-balanced (1).zip'\n"," \u001b[01;34msample_data\u001b[0m/       train_dir3class-balanced.zip\n"," \u001b[01;34mtrain_dir3class\u001b[0m/\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"Zl97oFz85YoX","colab_type":"code","colab":{}},"source":["# %cp -r \"/content/drive/My Drive/3is_project/GTRSB_kaggle/train_dir\" \"./\""],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"U3tpFZqTQ5f9","colab_type":"text"},"source":["###転移学習"]},{"cell_type":"code","metadata":{"id":"_Tk0VGoyfIg7","colab_type":"code","outputId":"a0051615-91ac-48b9-a896-9be5dd79ff94","executionInfo":{"status":"ok","timestamp":1576560481157,"user_tz":-540,"elapsed":1314,"user":{"displayName":"Yusuke Kori","photoUrl":"","userId":"11428297377331214421"}},"colab":{"base_uri":"https://localhost:8080/","height":34}},"source":["import torch\n","print(torch.__version__)\n","import torchvision\n","import torch.nn as nn\n","import torch.nn.init as init\n","import torch.optim as optim\n","import torch.nn.functional as F\n","from torch.optim import lr_scheduler\n","from torchvision import datasets, models, transforms\n","import numpy as np\n","\n","# print(PIL.__version__)"],"execution_count":0,"outputs":[{"output_type":"stream","text":["1.3.1\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"imP9yg2OSovE","colab_type":"text"},"source":["### imagefolder dataloader cv2_imshow"]},{"cell_type":"code","metadata":{"id":"6VXuJYDpQ-9X","colab_type":"code","colab":{}},"source":["\n","data_transforms = {\n","    'train': transforms.Compose([\n","        transforms.Resize((64,64)),\n","        transforms.RandomAffine(5,shear=20,fillcolor=(127,127,127)),\n","        transforms.RandomApply([transforms.CenterCrop(51)],0.7),\n","        transforms.RandomApply([transforms.Pad(10)],0.7),\n","        transforms.Resize((64,64)),\n","        transforms.ToTensor(),\n","        transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n","    ])\n","}\n","\n","data_dir = './train_dir3class'\n","train_dataset = datasets.ImageFolder(data_dir,data_transforms['train'])\n","train_loader = torch.utils.data.DataLoader(dataset=train_dataset,batch_size=256,shuffle=True,num_workers=4)"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"p21h7BVWS0xS","colab_type":"code","colab":{}},"source":["from  google.colab.patches import cv2_imshow\n","import cv2\n","for i ,(images,labels) in enumerate(train_loader):\n","  # print(labels.numpy())\n","  # img = torchvision.utils.make_grid(images,padding=1)\n","  img = images[0]\n","  img = img.numpy()\n","  img = np.transpose(img,(1,2,0))\n","  # print(images.shape)\n","  # print(images[0])\n","  cv2_imshow(cv2.cvtColor(img*255,cv2.COLOR_RGB2BGR))\n","  if(i>40):\n","    break"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"KH06VjXgSmc3","colab_type":"text"},"source":["### train"]},{"cell_type":"code","metadata":{"id":"nYYOMLWanDLy","colab_type":"code","colab":{}},"source":["device = \"cuda\" if torch.cuda.is_available() else \"cpu\""],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"bhCdnxZBz7G7","colab_type":"code","colab":{}},"source":["class My_model(nn.Module):\n","  def __init__(self):\n","    super(My_model,self).__init__()\n","    self.vgg = models.vgg19_bn(pretrained=True)\n","    for param in self.vgg.features[0:26].parameters():\n","       param.requires_grad = False\n","    for param in self.vgg.features[26:53].parameters():\n","       param.requires_grad = True\n","    num_ftrs = self.vgg.classifier[6].in_features\n","    self.vgg.classifier[6] = nn.Linear(num_ftrs, 3)\n","    \n","    \n","  def forward(self,x):\n","    x = self.vgg(x)\n","    # x = torch.sigmoid(x)\n","    return x\n"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"i_77rQXxRbcS","colab_type":"code","colab":{}},"source":["# model = models.vgg19(pretrained=True)\n","# model = models.vgg19(pretrained=False)\n","# model = model.to(device)\n","# model\n","model = My_model()\n","model = model.to(device)"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"GhmRR5HXcvFP","colab_type":"code","colab":{}},"source":["for p in model.vgg.classifier.parameters():\n","  print(p.requires_grad)"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"Ob4rsaz-99XE","colab_type":"code","colab":{}},"source":["model"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"qsLnHZKFpWxR","colab_type":"code","colab":{}},"source":["criterion = nn.CrossEntropyLoss()\n","# optimizer = optim.SGD(model.parameters(), lr=1e-4, momentum=0.9, weight_decay=5e-4)\n","optimizer = optim.Adam(model.parameters(), lr=1e-5, weight_decay=5e-4)\n","lr_scheduler = torch.optim.lr_scheduler.StepLR(optimizer, step_size=10, gamma=0.1)"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"6pYkLpWyqSBE","colab_type":"code","colab":{}},"source":["import nvidia_smi\n","!nvidia-smi"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"KA9X6ArSUJnu","colab_type":"code","colab":{}},"source":["!ps -elf | grep python"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"X2EX5N5nr73h","colab_type":"code","colab":{}},"source":["!ps aux\n","!kill -9 19"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"40D2QFakR_zq","colab_type":"code","outputId":"593b4af3-5093-427f-9345-7eb877ea299f","executionInfo":{"status":"ok","timestamp":1576564238442,"user_tz":-540,"elapsed":161822,"user":{"displayName":"Yusuke Kori","photoUrl":"","userId":"11428297377331214421"}},"colab":{"base_uri":"https://localhost:8080/","height":104}},"source":["num_epochs = 5\n","train_loss_list = []\n","train_acc_list = []\n","\n","for epoch in range(num_epochs):\n","    train_loss = 0\n","    train_acc = 0\n","    \n","    #train\n","    model.train()\n","    for i, (images, labels) in enumerate(train_loader):\n","      images,labels = images.to(device),labels.to(device)\n","      optimizer.zero_grad()\n","      outputs = model(images)\n","      loss = criterion(outputs, labels)\n","      train_loss += loss.item()\n","      train_acc += (outputs.max(1)[1] == labels).sum().item()\n","      loss.backward()\n","      optimizer.step()\n","    \n","    avg_train_loss = train_loss / len(train_loader.dataset)\n","    avg_train_acc = train_acc / len(train_loader.dataset)\n","\n","    print ('Epoch [{}/{}], Loss: {loss:.4f}, Acc: {acc:.4f}, lr：{learning_rate}' \n","                       .format(epoch+1, num_epochs , loss=avg_train_loss, acc=avg_train_acc,learning_rate=optimizer.param_groups[0][\"lr\"]))\n","    #学習率調整\n","    lr_scheduler.step()\n","    train_loss_list.append(avg_train_loss)\n","    train_acc_list.append(avg_train_acc)"],"execution_count":0,"outputs":[{"output_type":"stream","text":["Epoch [1/5], Loss: 0.0025, Acc: 0.7769, lr：1e-05\n","Epoch [2/5], Loss: 0.0003, Acc: 0.9833, lr：1e-05\n","Epoch [3/5], Loss: 0.0001, Acc: 0.9956, lr：1e-05\n","Epoch [4/5], Loss: 0.0000, Acc: 0.9976, lr：1e-05\n","Epoch [5/5], Loss: 0.0000, Acc: 0.9997, lr：1e-05\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"LjqDkyFXstxE","colab_type":"text"},"source":["### model save ,load"]},{"cell_type":"code","metadata":{"id":"BKXoCIe9S6iq","colab_type":"code","colab":{}},"source":["torch.save(model.state_dict(), '/content/drive/My Drive/3is_project/GTRSB_kaggle/models/12_17_fined.model')"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"OylcMDfKwOJd","colab_type":"code","outputId":"7498e4e5-1c61-48a8-eb75-6e54b9af08e7","executionInfo":{"status":"ok","timestamp":1576563617107,"user_tz":-540,"elapsed":3736,"user":{"displayName":"Yusuke Kori","photoUrl":"","userId":"11428297377331214421"}},"colab":{"base_uri":"https://localhost:8080/","height":34}},"source":["# 12_11_fined3 -> sigmoid;  12_11_fined2 -> linear\n","model = My_model()\n","param = torch.load('/content/drive/My Drive/3is_project/GTRSB_kaggle/models/12_17_fined.model')\n","model.load_state_dict(param)"],"execution_count":0,"outputs":[{"output_type":"execute_result","data":{"text/plain":["<All keys matched successfully>"]},"metadata":{"tags":[]},"execution_count":94}]},{"cell_type":"code","metadata":{"colab_type":"code","outputId":"ea15cff6-04df-4165-8717-96aa0ef9ced4","executionInfo":{"status":"ok","timestamp":1576510493618,"user_tz":-540,"elapsed":3697,"user":{"displayName":"Yusuke Kori","photoUrl":"","userId":"11428297377331214421"}},"id":"IUPupMjjonfC","colab":{"base_uri":"https://localhost:8080/","height":69}},"source":["ls '/content/drive/My Drive/3is_project/GTRSB_kaggle/models/'"],"execution_count":0,"outputs":[{"output_type":"stream","text":["12_11_fined2.model  12_15_fined.model      class3_12_6_fined.h5\n","12_11_fined3.model  class3_11_28_fined.h5  test2.model\n","12_11_fined.model   class3_11_28.h5        test.model\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"3uZMKMGs0ypA","colab_type":"text"},"source":["## area detection"]},{"cell_type":"markdown","metadata":{"colab_type":"text","id":"xWtzq8KGpXBD"},"source":["### image cuts"]},{"cell_type":"code","metadata":{"colab_type":"code","id":"2sU6OIwGpXBJ","colab":{}},"source":["def upCut(path,verbose=False):\n","  import numpy as np\n","  import cv2\n","  import time\n","  if type(path) == str:\n","    start= time.time()\n","    img = cv2.imread(path)\n","    print(f\"file load:{time.time() - start}\")\n","    img = cv2.resize(img , dsize=(640, 480))\n","  else: \n","    img = path\n","  \n","  img = img[0:int(len(img)/3),:,:]\n","  if verbose:\n","   cv2.imshow(img)\n","  return img\n","\n","def rightCut(path,ratio,idx,verbose=False):\n","  from google.colab.patches import cv2_imshow\n","  import numpy as np\n","  import cv2\n","  if type(path) == str:\n","    img = cv2.imread(path)\n","    img = cv2.resize(img , dsize=(640, 480))\n","  else: \n","    img = path \n","  img = img[:,int(len(img[0])/ratio)*idx:int(len(img[0])/ratio)*(idx+1),:]\n","  if verbose:\n","    cv2_imshow(img)\n","  return img"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"jZ0_96x4pbpa","colab_type":"text"},"source":["### simplize"]},{"cell_type":"code","metadata":{"id":"6mPv5D9-poTa","colab_type":"code","colab":{}},"source":["def simplize(path,verbose=False): \n","  from google.colab.patches import cv2_imshow\n","  import numpy as np\n","  import cv2\n","  if type(path) == str:\n","    img = cv2.imread(path)\n","    img = cv2.resize(img , dsize=(640, 480))\n","  else: \n","    img = path\n","  ## HSVFULLじゃないことに注意！！\n","  hsv = cv2.cvtColor(img ,cv2.COLOR_BGR2HSV)\n","  ## red 160 - 19 yellow 20-39 green 40 - 79 cyan 80 - 99 blue 100 - 139  biolet 140-159  \n","  hsv[:,:,0]=np.where( (160 <= hsv[:,:,0]) | (hsv[:,:,0] <= 19),0,hsv[:,:,0])#red\n","  hsv[:,:,0]=np.where( (20 <= hsv[:,:,0]) & (hsv[:,:,0] <= 39),30,hsv[:,:,0])#yellow\n","  hsv[:,:,0]=np.where( (40 <= hsv[:,:,0]) & (hsv[:,:,0] <= 79),60,hsv[:,:,0])#green\n","  hsv[:,:,0]=np.where( (80 <= hsv[:,:,0]) & (hsv[:,:,0] <= 99),90,hsv[:,:,0])#cyan\n","  hsv[:,:,0]=np.where( (100 <= hsv[:,:,0]) & (hsv[:,:,0] <= 139),120,hsv[:,:,0])#blue\n","  hsv[:,:,0]=np.where( (140 <= hsv[:,:,0]) & (hsv[:,:,0] <= 159),150,hsv[:,:,0])#violet\n","  ### 彩度の範囲を広げると白色が検出しづらくなる。明度を広げると薄い色が検出しづらくなる。\n","  hsv[:,:,1]=np.where( (hsv[:,:,1] <= 60) & (160 <= hsv[:,:,2]  )  ,0,hsv[:,:,1]) #white \n","  hsv[:,:,2]=np.where( hsv[:,:,2] <=  100, 0,hsv[:,:,2]) #black # flatten all colors\n","  if verbose:\n","    cv2_imshow(cv2.cvtColor(hsv,cv2.COLOR_HSV2BGR))\n","  return cv2.cvtColor(hsv,cv2.COLOR_HSV2BGR)\n"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"fEgVMPHlfA4f","colab_type":"code","colab":{}},"source":["def rb_filter(path,verbose=False):\n","  if type(path) == str:\n","    img = cv2.imread(path)\n","    img = cv2.resize(img , dsize=(640, 480))\n","  else: \n","    img = path\n","  if verbose:\n","    cv2_imshow(img)\n","  hsv = cv2.cvtColor(img, cv2.COLOR_BGR2HSV)\n","  hsv[:,:,2]=np.where( ((hsv[:,:,0] == 0)|(hsv[:,:,0]==150)|(hsv[:,:,0] == 120)|(hsv[:,:,0]==90)) & (hsv[:,:,1]  > 30 ), 255,0)\n","  img = cv2.cvtColor(hsv,cv2.COLOR_HSV2BGR)\n","  if verbose:\n","    cv2_imshow(img)\n","  return img\n"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"UiXaZ23b40u2","colab_type":"text"},"source":["###selective search"]},{"cell_type":"code","metadata":{"id":"GP09ne4ATTzf","colab_type":"code","colab":{}},"source":["import skimage.io\n","import skimage.feature\n","import skimage.color\n","import skimage.transform\n","import skimage.util\n","import skimage.segmentation\n","import numpy\n","import time\n","\n","def _generate_segments(im_orig, scale, sigma, min_size):\n","    \"\"\"\n","        segment smallest regions by the algorithm of Felzenswalb and\n","        Huttenlocher\n","    \"\"\"\n","\n","    # open the Image\n","    im_mask = skimage.segmentation.felzenszwalb(\n","        im_orig, scale=scale, sigma=sigma,\n","        min_size=min_size)\n","\n","    # merge mask channel to the image as a 4th channel\n","\n","    im_orig = numpy.append(\n","        im_orig, numpy.zeros((len(im_orig),len(im_orig[0])))[:, :, numpy.newaxis], axis=2)\n","    im_orig[:, :, 3] = im_mask\n","    return im_orig\n","\n","\n","def _sim_colour(r1, r2):\n","    \"\"\"\n","        calculate the sum of histogram intersection of colour\n","    \"\"\"\n","    return sum([min(a, b) for a, b in zip(r1[\"hist_c\"], r2[\"hist_c\"])])\n","\n","\n","def _sim_texture(r1, r2):\n","    \"\"\"\n","        calculate the sum of histogram intersection of texture\n","    \"\"\"\n","    return sum([min(a, b) for a, b in zip(r1[\"hist_t\"], r2[\"hist_t\"])])\n","\n","\n","def _sim_size(r1, r2, imsize):\n","    \"\"\"\n","        calculate the size similarity over the image\n","    \"\"\"\n","    return 1.0 - (r1[\"size\"] + r2[\"size\"]) / imsize\n","\n","\n","def _sim_fill(r1, r2, imsize):\n","    \"\"\"\n","        calculate the fill similarity over the image\n","    \"\"\"\n","    bbsize = (\n","        (max(r1[\"max_x\"], r2[\"max_x\"]) - min(r1[\"min_x\"], r2[\"min_x\"]))\n","        * (max(r1[\"max_y\"], r2[\"max_y\"]) - min(r1[\"min_y\"], r2[\"min_y\"]))\n","    )\n","    return 1.0 - (bbsize - r1[\"size\"] - r2[\"size\"]) / imsize\n","\n","\n","def _calc_sim(r1, r2, imsize):\n","    return (_sim_colour(r1, r2) + _sim_texture(r1, r2)\n","            + _sim_size(r1, r2, imsize) + _sim_fill(r1, r2, imsize))\n","\n","\n","def _calc_colour_hist(img):\n","    BINS = 25\n","    hist = numpy.array([])\n","    for colour_channel in (0, 1, 2):\n","        # extracting one colour channel\n","        c = img[:, colour_channel]\n","        # calculate histogram for each colour and join to the result\n","        hist = numpy.concatenate(\n","            [hist] + [numpy.histogram(c, BINS, (0.0, 255.0))[0]])\n","    # L1 normalize\n","    hist = hist / len(img)\n","\n","    return hist\n","\n","\n","def _calc_texture_gradient(img):\n","    ret = numpy.zeros((img.shape[0], img.shape[1], img.shape[2]))\n","    for colour_channel in (0, 1, 2):\n","        ret[:, :, colour_channel] = skimage.feature.local_binary_pattern(\n","            img[:, :, colour_channel], 8, 1.0)\n","    return ret\n","\n","\n","def _calc_texture_hist(img):\n","    BINS = 10\n","    hist = numpy.array([])\n","\n","    for colour_channel in (0, 1, 2):\n","\n","        # mask by the colour channel\n","        fd = img[:, colour_channel]\n","\n","        # calculate histogram for each orientation and concatenate them all\n","        # and join to the result\n","        hist = numpy.concatenate(\n","            [hist] + [numpy.histogram(fd, BINS, (0.0, 1.0))[0]])\n","\n","    # L1 Normalize\n","    hist = hist / len(img)\n","\n","    return hist\n","\n","\n","def _extract_regions(img):\n","    R = {}\n","    hsv = skimage.color.rgb2hsv(img[:, :, :3])\n","    for y, i in enumerate(img):\n","        for x, (r, g, b, l) in enumerate(i):\n","            if l not in R:\n","                R[l] = {\n","                    \"min_x\": 0xffff, \"min_y\": 0xffff,\n","                    \"max_x\": 0, \"max_y\": 0, \"labels\": l}\n","            if R[l][\"min_x\"] > x:\n","                R[l][\"min_x\"] = x\n","            if R[l][\"min_y\"] > y:\n","                R[l][\"min_y\"] = y\n","            if R[l][\"max_x\"] < x:\n","                R[l][\"max_x\"] = x\n","            if R[l][\"max_y\"] < y:\n","                R[l][\"max_y\"] = y\n","    tex_grad = _calc_texture_gradient(img)\n","    for k, v in list(R.items()):\n","        masked_pixels = hsv[:, :, :][img[:, :, 3] == k]\n","        R[k][\"size\"] = len(masked_pixels / 4)\n","        R[k][\"hist_c\"] = _calc_colour_hist(masked_pixels)\n","        R[k][\"hist_t\"] = _calc_texture_hist(tex_grad[:, :][img[:, :, 3] == k])\n","    return R\n","\n","\n","def _extract_neighbours(regions):\n","    def intersect(a, b):\n","        if (a[\"min_x\"] < b[\"min_x\"] < a[\"max_x\"]\n","                and a[\"min_y\"] < b[\"min_y\"] < a[\"max_y\"]) or (\n","            a[\"min_x\"] < b[\"max_x\"] < a[\"max_x\"]\n","                and a[\"min_y\"] < b[\"max_y\"] < a[\"max_y\"]) or (\n","            a[\"min_x\"] < b[\"min_x\"] < a[\"max_x\"]\n","                and a[\"min_y\"] < b[\"max_y\"] < a[\"max_y\"]) or (\n","            a[\"min_x\"] < b[\"max_x\"] < a[\"max_x\"]\n","                and a[\"min_y\"] < b[\"min_y\"] < a[\"max_y\"]):\n","            return True\n","        return False\n","    R = list(regions.items())\n","    neighbours = []\n","    for cur, a in enumerate(R[:-1]):\n","        for b in R[cur + 1:]:\n","            if intersect(a[1], b[1]):\n","                neighbours.append((a, b))\n","    return neighbours\n","def _merge_regions(r1, r2):\n","    new_size = r1[\"size\"] + r2[\"size\"]\n","    rt = {\n","        \"min_x\": min(r1[\"min_x\"], r2[\"min_x\"]),\n","        \"min_y\": min(r1[\"min_y\"], r2[\"min_y\"]),\n","        \"max_x\": max(r1[\"max_x\"], r2[\"max_x\"]),\n","        \"max_y\": max(r1[\"max_y\"], r2[\"max_y\"]),\n","        \"size\": new_size,\n","        \"hist_c\": (\n","            r1[\"hist_c\"] * r1[\"size\"] + r2[\"hist_c\"] * r2[\"size\"]) / new_size,\n","        \"hist_t\": (\n","            r1[\"hist_t\"] * r1[\"size\"] + r2[\"hist_t\"] * r2[\"size\"]) / new_size,\n","        \"labels\": r1[\"labels\"] + r2[\"labels\"]\n","    }\n","    return rt\n","def selective_search(im_orig, scale=1.0, sigma=0.8, min_size=50):\n","    assert im_orig.shape[2] == 3, \"3ch image is expected\"\n","    img = _generate_segments(im_orig, scale, sigma, min_size)\n","    if img is None:\n","        return None, {}\n","    imsize = img.shape[0] * img.shape[1]\n","    R = _extract_regions(img)\n","    neighbours = _extract_neighbours(R)\n","    S = {}\n","    for (ai, ar), (bi, br) in neighbours:\n","        S[(ai, bi)] = _calc_sim(ar, br, imsize)\n","    while S != {}:\n","        i, j = sorted(S.items(), key=lambda i: i[1])[-1][0]\n","        t = max(R.keys()) + 1.0\n","        R[t] = _merge_regions(R[i], R[j])\n","        key_to_delete = []\n","        for k, v in list(S.items()):\n","            if (i in k) or (j in k):\n","                key_to_delete.append(k)\n","        for k in key_to_delete:\n","            del S[k]\n","        for k in [a for a in key_to_delete if a != (i, j)]:\n","            n = k[1] if k[0] in (i, j) else k[0]\n","            S[(t, n)] = _calc_sim(R[t], R[n], imsize)\n","    regions = []\n","    for r in R.values():\n","      w = r['max_x'] - r['min_x']\n","      h = r['max_y'] - r['min_y']\n","      ratio = h/w if w>=h else w/h\n","      if( ratio>=0.8 and w*h > 1000 and w*h < 5000):\n","        regions.append({\n","              'x_':r['min_x'], \n","              'y_':r['min_y'],\n","              '_x':r['max_x'],\n","              '_y':r['max_y'],\n","              'area': w*h,\n","        })\n","    sort = sorted(regions, key=lambda x:x[\"area\"],reverse=True)\n","    idx=0\n","    ## non maximum suppression\n","    for i1, r1 in enumerate(sort):\n","      idx = i1 + 1\n","      for r2 in sort[i1+1:]:\n","        if r1[\"x_\"] <= r2[\"x_\"] and r1[\"_x\"] >= r2[\"_x\"] and r1[\"y_\"] <= r2[\"y_\"] and r1[\"_y\"] >= r2[\"_y\"]:    \n","          del sort[idx]\n","          idx -= 1\n","        idx += 1 \n","    return img, sort"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"5cUP0Z-ZTL-1","colab_type":"text"},"source":["### road sign recog"]},{"cell_type":"code","metadata":{"id":"uUi7wgJTrBIq","colab_type":"code","colab":{}},"source":["device= \"cuda\"\n","model = model.eval()\n","model = model.to(device)\n","def classify_torch(model,detected,exam=True):\n","  from google.colab.patches import cv2_imshow\n","  import cv2\n","  import time\n","  if exam:\n","    cv2_imshow(detected)\n","  image = cv2.cvtColor(detected , cv2.COLOR_BGR2RGB)\n","  trf = transforms.Compose([\n","    transforms.ToPILImage(),\n","    transforms.Resize((64,64)), \n","    transforms.ToTensor(), \n","    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n","    ])\n","  image=trf(image)\n","  image = image.view(1,3,64,64)\n","  image = image.float()\n","  image = image.to(device)\n","  \n","  start = time.time()\n","  output= model(image)\n","  print(f\"recog time: {time.time()-start}\")\n","  clas = pprint(output,exam)\n","  return clas"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"k6GJeMGNs9ag","colab_type":"code","colab":{}},"source":["def classify(model,detected,exam=True):\n","  from google.colab.patches import cv2_imshow\n","  import cv2\n","  import time\n","  image = cv2.resize(detected , dsize=(64, 64))\n","  if exam:\n","    cv2_imshow(image)\n","  image = cv2.cvtColor(image , cv2.COLOR_BGR2RGB)\n","  image = image.reshape((1,) + image.shape)\n","  image = image / 255\n","  start = time.time()\n","  clas = pprint(model.predict(image),exam)\n","  print(f\" recog time:{time.time() - start}\")\n","  return clas\n"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"BnXaxvdztHYK","colab_type":"code","colab":{}},"source":["def pprint(arr,exam=True):\n","  print(f\" {arr}\")\n","  diff = abs(arr[0][0]-arr[0][1]-arr[0][2])\n","  idx = arr[0].argmax()\n","  if exam:\n","    print(f\" difference = {diff}\")\n","  if arr[0][idx]<5 or arr[0][(idx+1)%3]>0 or arr[0][(idx+2)%3]>0 :\n","  # if diff<0.7 :\n","    print(\" Others\")\n","    return 3\n","  elif arr.argmax() == 0:\n","    print(\" Speed restriction 30\")\n","    return 0\n","  elif arr.argmax() == 1:\n","    print(\" GO\")\n","    return 1\n","  elif arr.argmax() == 2:\n","    print(\" STOP\")\n","    return 2"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"6seeNyYHfPpp","colab_type":"text"},"source":["**対象を一つ検出したら検索を切り上げる**"]},{"cell_type":"code","metadata":{"id":"tavwZxO7qI2a","colab_type":"code","outputId":"54261fa7-142c-4fb7-f0a2-c80c5af63e8d","executionInfo":{"status":"ok","timestamp":1576568730330,"user_tz":-540,"elapsed":1088,"user":{"displayName":"Yusuke Kori","photoUrl":"","userId":"11428297377331214421"}},"colab":{"base_uri":"https://localhost:8080/","height":227}},"source":["def s_search(path,exam=True):\n","  from google.colab.patches import cv2_imshow\n","  import numpy as np\n","  import cv2\n","  import time \n","  print(f\"\\nimage path = {path}\")\n","  s = time.perf_counter()\n","  cut = rightCut(upCut(pth),3,idx=0,verbose=False)\n","  img = simplize(cut,False)\n","  img = rb_filter(img,False)\n","  img = cv2.medianBlur(img,5)\n","  img = cv2.GaussianBlur(img,(17,17),0,0)\n","  print(f\"maeshori:{time.perf_counter()-s}\")\n","  print(\"_______SEARCH START_______\")\n","  start = time.perf_counter()\n","  _, regions = selective_search(img.astype(np.float64), scale=3000, sigma=0.0, min_size=100)\n","  print(f\" search time:{time.perf_counter() - start}\")\n","  for r in regions:\n","    start = time.perf_counter()\n","    c = classify_torch(model,cut[r[\"y_\"]:r[\"_y\"],r[\"x_\"]:r[\"_x\"],:],exam)\n","    print(f\"recog time:{time.perf_counter() - start}\")\n","    if c!=3:\n","      return c\n","  return c\n","# pth = \"/content/drive/My Drive/3is_project/GTRSB_kaggle/vali_dir00_speed/speed_img_000.jpg\"\n","pth = \"/content/drive/My Drive/3is_project/GTRSB_kaggle/micon_images/micon_img_320.jpg\"\n","# pth = \"/content/drive/My Drive/3is_project/GTRSB_kaggle/micon_images/micon_img_520.jpg\"\n","# pth = \"/content/drive/My Drive/3is_project/GTRSB_kaggle/output2.jpg\"\n","# pth = \"/content/drive/My Drive/3is_project/GTRSB_kaggle/win_images/20191201/win_img_000.jpg\"\n","# pth = \"/content/drive/My Drive/3is_project/GTRSB_kaggle/win_images/20191201/win_img_010.jpg\"\n","# pth = \"/content/drive/My Drive/3is_project/GTRSB_kaggle/win_images/20191201/win_img_020.jpg\"\n","# pth = '/content/drive/My Drive/3is_project/GTRSB_kaggle/win_images/20191129_17_03_16/win_img_1600.jpg'\n","import time\n","start=time.perf_counter()\n","sign = s_search(pth,False)\n","print(f\"about time:{time.perf_counter() -start}\")\n","print(sign)"],"execution_count":0,"outputs":[{"output_type":"stream","text":["\n","image path = /content/drive/My Drive/3is_project/GTRSB_kaggle/micon_images/micon_img_320.jpg\n","file load:0.023802757263183594\n","maeshori:0.03359986299983575\n","_______SEARCH START_______\n"," search time:0.1780810919990472\n","recog time: 0.0041162967681884766\n"," tensor([[ 6.6357, -6.9466, -2.5718]], device='cuda:0', grad_fn=<AddmmBackward>)\n"," Speed restriction 30\n","recog time:0.0224391209994792\n","about time:0.23584562399992137\n","0\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"prQCXtUDb9CA","colab_type":"text"},"source":["**動作確認用**"]},{"cell_type":"code","metadata":{"id":"0m5-UbsWbYeH","colab_type":"code","outputId":"c6550b97-0f63-4a88-8440-f75dd907abf5","executionInfo":{"status":"ok","timestamp":1576564306791,"user_tz":-540,"elapsed":51783,"user":{"displayName":"Yusuke Kori","photoUrl":"","userId":"11428297377331214421"}},"colab":{"base_uri":"https://localhost:8080/","height":1000,"output_embedded_package_id":"1pyHHitFaBp2wwyjnOYnplrW1oZ1tq9lQ"}},"source":["def s_search(path,exam=True):\n","  from google.colab.patches import cv2_imshow\n","  import numpy as np\n","  import cv2\n","  # import selectivesearch\n","  import time \n","  begin = time.time()\n","  print(f\"\\nimage path = {path}\")\n","  for j in range(3):\n","    s = time.time()\n","    cut = rightCut(upCut(path),3,idx=j,verbose=False)\n","    img = simplize(cut,True)\n","    img = rb_filter(img,False)\n","    img = cv2.medianBlur(img,5)\n","    img = cv2.GaussianBlur(img,(17,17),0,0)\n","    print(f\"maeshori:{time.time()-s}\")\n","    print(\"_______SEARCH START_______\")\n","    start = time.time()\n","    _, regions = selective_search(img.astype(np.float64), scale=3000, sigma=0, min_size=100)\n","    print(f\" search time:{time.time() - start}\")\n","    for r in regions:\n","      start = time.time()\n","      c = classify_torch(model,cut[r[\"y_\"]:r[\"_y\"],r[\"x_\"]:r[\"_x\"],:],exam)\n","      print(f\"recog time:{time.time() - start}\")\n","      if c!=3:\n","        cv2.rectangle(cut, (r[\"x_\"], r[\"y_\"]), (r[\"_x\"], r[\"_y\"]), (0, 0, 255), 2)\n","        cv2_imshow(cut)\n","    print(f\"about time:{time.time() -begin}\")\n","\n","import os \n","dire = \"/content/drive/My Drive/3is_project/GTRSB_kaggle/micon_images/\"\n","images = os.listdir(dire)\n","for i in images:\n","  img = dire + i\n","  s_search(img,False)"],"execution_count":0,"outputs":[{"output_type":"display_data","data":{"text/plain":"Output hidden; open in https://colab.research.google.com to view."},"metadata":{}}]},{"cell_type":"code","metadata":{"id":"aJfXV5wNpCWG","colab_type":"code","colab":{}},"source":[""],"execution_count":0,"outputs":[]}]}
